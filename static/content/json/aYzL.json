{
  "uuid": "aYzL",
  "titre": "\\'Etude d'une méthode de Monte Carlo",
  "theme": "probabilités",
  "auteur": "Maxime Nguyen",
  "date": "",
  "organisation": "AMSCC",
  "contenu": [
    {
      "type": "texte",
      "value": "<p>On souhaite calculer à l’aide d’une méthode de Monte Carlo une\napproximation de l’intégrale <span class=\"math display\">\\[I=\\int_0^1\n\\sin(\\sqrt{x})dx\\]</span> Soit <span class=\"math inline\">\\((X_i)_{i \\in\n\\mathbb{N}^*}\\)</span> une suite de variables aléatoires indépendantes\nidentiquement distribuées selon une loi uniforme <span\nclass=\"math inline\">\\(\\mathcal{U}([0;1])\\)</span>.</p>\n"
    },
    {
      "type": "question",
      "value": "<p>Démontrer que si on définit la suite de variables aléatoires <span\nclass=\"math inline\">\\((I_n)\\)</span> par <span\nclass=\"math display\">\\[I_n = \\frac{1}{n}\\sum_{k=1}^n \\sin\\left(\n\\sqrt{X_k} \\right)\\]</span> alors la suite <span\nclass=\"math inline\">\\((I_n)\\)</span> converge presque sûrement vers la\nconstante <span class=\"math inline\">\\(I\\)</span>.</p>\n"
    },
    {
      "type": "reponse",
      "value": "<p>Les variables <span class=\"math inline\">\\(\\left(\\sin\\left( \\sqrt{X_k}\n\\right) \\right)_i\\)</span> sont indépendantes et identiquement\ndistribuées, elles admettent en outre une espérance qui se calcule à\nl’aide du théorème de transfert. Soit <span\nclass=\"math inline\">\\(f\\)</span> la densité d’une loi uniforme sur <span\nclass=\"math inline\">\\([0;1]\\)</span>. Alors <span\nclass=\"math inline\">\\(\\mathbb{E}(X_1) = \\int \\sin\\left( \\sqrt{x} \\right)\nf(x)dx = \\int_0^1 \\sin\\left( \\sqrt{x} \\right)dx = I\\)</span>.</p>\n<p>D’après la loi forte de grands nombres, la suite de variables\naléatoires <span class=\"math inline\">\\((I_n)\\)</span> converge donc\npresque sûrement vers <span class=\"math inline\">\\(\\mathbb{E}(X_1) =\nI\\)</span>.</p>\n"
    },
    {
      "type": "question",
      "value": "<p>Compléter le code Python ci-dessous, comportant deux champs\nmanquants, afin qu’il affiche une approximation de <span\nclass=\"math inline\">\\(I\\)</span>.</p>\n"
    },
    {
      "type": "reponse",
      "value": "\n"
    },
    {
      "type": "texte",
      "value": "<p>Pour tout <span class=\"math inline\">\\(k \\in \\mathbb{N}^*\\)</span>, on\npose <span class=\"math inline\">\\(Y_k= \\sin\\left( \\sqrt{X_k}\n\\right)\\)</span>. Les variables aléatoires <span\nclass=\"math inline\">\\((X_k)\\)</span> étant i.i.d., les variables\naléatoires <span class=\"math inline\">\\((Y_k)\\)</span> le sont aussi et\non note <span class=\"math inline\">\\(\\mu\\)</span> leur espérance et <span\nclass=\"math inline\">\\(\\sigma^2\\)</span> leur variance.</p>\n"
    },
    {
      "type": "question",
      "value": "<p>Calculer l’espérance et la variance de la variable aléatoire <span\nclass=\"math inline\">\\(I_n\\)</span> en fonction de <span\nclass=\"math inline\">\\(\\mu\\)</span>, <span\nclass=\"math inline\">\\(\\sigma\\)</span> et <span\nclass=\"math inline\">\\(n\\)</span>.</p>\n"
    },
    {
      "type": "reponse",
      "value": "<p>Par linéarité de l’espérance, <span\nclass=\"math inline\">\\(\\mathbb{E}(I_n) = \\frac{1}{n} \\times n \\times I\n=I\\)</span>. Par propriétés de la variance et indépendance des variables\ndans la somme, <span class=\"math inline\">\\(V(I_n) = \\frac{1}{n^2} \\times\nn \\times V(Y_1) = \\frac{V(Y_1)}{n} = \\frac{\\sigma^2}{n}\\)</span>.</p>\n"
    },
    {
      "type": "question",
      "value": "<p>Déterminer, en justifiant, une approximation de la loi de la variable\naléatoire <span\nclass=\"math display\">\\[\\frac{\\sqrt{n}}{\\sigma}(I_n-I)\\]</span> lorsque\n<span class=\"math inline\">\\(n\\)</span> est suffisamment grand.</p>\n"
    },
    {
      "type": "reponse",
      "value": "<p>Les variables <span class=\"math inline\">\\(Y_k\\)</span> sont\nindépendantes, identiquement distribuées, admettent une espérance et une\nvariance finies, donc d’après le Théorème Central Limite, la variable\n<span class=\"math display\">\\[\\frac{\\frac{1}{n}\\sum_{k=1}^n Y_k -\nI  }{\\frac{\\sigma}{\\sqrt{n}}} =\n            \\frac{ \\sum_{k=1}^n \\frac{Y_k}{n} -\n\\mathbb{E}\\left(\\sum_{k=1}^n \\frac{Y_k}{n}  \\right)\n}{\\sigma\\left(\\sum_{k=1}^n \\frac{Y_k}{n}  \\right)}\\]</span> suit\napproximativement une loi normale centrée réduite.</p>\n"
    },
    {
      "type": "question",
      "value": "<p>En déduire le nombre d’itérations <span\nclass=\"math inline\">\\(N_0\\)</span> (dépendant de <span\nclass=\"math inline\">\\(\\sigma\\)</span>) à partir duquel la suite <span\nclass=\"math inline\">\\((I_n)\\)</span> réalise une approximation de <span\nclass=\"math inline\">\\(I\\)</span> à <span\nclass=\"math inline\">\\(10^{-3}\\)</span> près avec une confiance de <span\nclass=\"math inline\">\\(95\\%\\)</span>.</p>\n"
    },
    {
      "type": "reponse",
      "value": "<p>On cherche le rang à partir duquel <span\nclass=\"math inline\">\\(\\PP(|I_n-I|&lt;\\varepsilon) \\geq 0.95\\)</span> où\n<span class=\"math inline\">\\(\\varepsilon = 10^{-3}\\)</span>. Or <span\nclass=\"math display\">\\[\\begin{align*}\n                \\PP(|I_n-I|&lt;\\varepsilon) &amp;= \\PP(-\\varepsilon &lt;\nI_n-I &lt; \\varepsilon) \\\\\n                &amp;= \\PP\\left(-\\frac{\\sqrt{n}}{\\sigma}\\varepsilon &lt;\n\\frac{\\sqrt{n}}{\\sigma} (I_n-I) &lt; \\frac{\\sqrt{n}}{\\sigma}\\varepsilon\n\\right) \\\\\n                &amp;\\approx\n\\PP\\left(-\\frac{\\sqrt{n}}{\\sigma}\\varepsilon &lt; Z &lt;\n\\frac{\\sqrt{n}}{\\sigma}\\varepsilon \\right) \\text{ où } Z \\sim\n\\mathcal{N}(0,1)\n            \\end{align*}\\]</span> Or par lecture de tables, <span\nclass=\"math inline\">\\(\\PP(-1.96 &lt; Z &lt; 1.96) \\approx 0.95\\)</span>\ndonc il suffit de prendre <span class=\"math inline\">\\(n\\)</span> tel que\n<span class=\"math inline\">\\(\\frac{\\sqrt{n}}{\\sigma}\\varepsilon \\geq\n1.96\\)</span> i.e. <span class=\"math display\">\\[n \\geq 10^6 \\left(1.96\n\\sigma\\right)^2\\]</span></p>\n"
    },
    {
      "type": "question",
      "value": "<p>Soit la variable <span class=\"math display\">\\[V_n = \\frac{1}{2n}\n\\sum_{k=1}^n (Y_{2k}-Y_{2k-1})^2\\]</span> Vérifier que la suite <span\nclass=\"math inline\">\\((V_n)\\)</span> permet d’approcher la valeur de\n<span class=\"math inline\">\\(\\sigma^2\\)</span>.</p>\n"
    },
    {
      "type": "reponse",
      "value": "<p>On calcule <span class=\"math display\">\\[\\begin{align*}\n                \\mathbb{E}((Y_{2k}-Y_{2k-1})^2) &amp;=\n\\mathbb{E}(Y_{2k}^2-2Y_{2k}Y_{2k-1} + Y_{2k-1}^2) \\\\\n                &amp;= \\mathbb{E}(Y_{2k}^2) - 2\n\\mathbb{E}(Y_{2k}Y_{2k-1}) +\\mathbb{E}(Y_{2k-1}^2) \\text{ par linéarité\n} \\\\\n                &amp;= 2\\mathbb{E}(Y_{2k}^2)- 2\n\\mathbb{E}(Y_{2k}Y_{2k-1}) \\text{ par identique distribution } \\\\\n                &amp;= 2\\mathbb{E}(Y_{2k}^2)- 2\n\\mathbb{E}(Y_{2k})  \\mathbb{E}(Y_{2k-1}) \\text{ par indépendance} \\\\\n                &amp;= 2\\mathbb{E}(Y_{2k}^2)- 2 \\mathbb{E}(Y_{2k})^2 \\\\\n                &amp;= 2\\mathbb{E}(Y_{1}^2)- 2 \\mathbb{E}(Y_{1})^2 \\\\\n                &amp;= 2V(Y_1)\n            \\end{align*}\\]</span> donc d’après la loi forte des grands\nnombres, <span class=\"math inline\">\\(\\frac{1}{n} \\sum_{k=1}^n\n(Y_{2k}-Y_{2k-1})^2\\)</span> converge simplement vers <span\nclass=\"math inline\">\\(2V(Y_1)\\)</span>, ce qui répond à la question\nposée.</p>\n"
    }
  ]
}