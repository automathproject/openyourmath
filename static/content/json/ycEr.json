{
  "uuid": "ycEr",
  "titre": "Regression linéaire",
  "theme": "Optimisation",
  "auteur": "Erwan HILLION",
  "date": "",
  "organisation": "AMSCC",
  "contenu": [
    {
      "type": "texte",
      "value": "<p>On dispose d’observations <span class=\"math inline\">\\((x_1,y_1),\\ldots,(x_n,y_n)\\)</span>. On cherche les \"meilleurs\" coefficients <span class=\"math inline\">\\(a\\)</span> et <span class=\"math inline\">\\(b\\)</span> tels que pour chaque observation, on ait <span class=\"math inline\">\\(y_i \\approx a x_i + b\\)</span>. Ce problème est appelé régression linéaire simple.</p>\n<p>Pour mesurer la qualité des paramètres <span class=\"math inline\">\\((a,b)\\)</span>, on souhaite que l’écart entre <span class=\"math inline\">\\(y_i\\)</span> et <span class=\"math inline\">\\(ax_i+b\\)</span> soit faible pour chaque observation. Pour quantifier l’erreur, on utilise le risque quadratique : <span class=\"math display\">\\[R(a,b) = \\sum_{i=1}^n (y_i - (a x_i+b) )^2.\\]</span> Le problème est de minimiser la fonction <span class=\"math inline\">\\(R(a,b)\\)</span>.</p>\n"
    }
  ]
}