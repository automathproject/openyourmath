{
  "uuid": "CXE4",
  "titre": "Rétropropagation à une variable",
  "theme": [
    "réseaux de neurones"
  ],
  "niveau": "",
  "metadata": {
    "auteur": "Maxime NGUYEN",
    "createdAt": "2024-12-17T17:05:07.149Z",
    "organisation": "AMSCC",
    "updatedAt": "2024-12-17T17:05:07.149Z"
  },
  "contenu": [
    {
      "id": "842a962b-168d-4538-8055-cefbfea09ac9",
      "type": "description",
      "value": {
        "latex": "Vous allez travailler avec un réseau de neurones à une couche cachée, conçu pour effectuer une tâche de prédiction simple. \n\t\n\t\n\t\n\t\\textbf{Description du réseau}\n\t\n\t\\begin{itemize}\n\t\t\\item \\textbf{Entrée :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\( x \\in \\mathbb{R} \\) (scalaire)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Couche cachée (2 neurones) :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Neurone caché 1 :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_1 = 0{,}15 \\)\n\t\t\t\t\\item Biais : \\( b_1 = 0{,}35 \\)\n\t\t\t\\end{itemize}\n\t\t\t\\item \\textbf{Neurone caché 2 :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_2 = 0{,}20 \\)\n\t\t\t\t\\item Biais : \\( b_2 = 0{,}35 \\)\n\t\t\t\\end{itemize}\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Couche de sortie (1 neurone) :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Neurone de sortie :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_3 = 0{,}40 \\) (connecté au neurone caché 1)\n\t\t\t\t\\item Poids : \\( w_4 = 0{,}45 \\) (connecté au neurone caché 2)\n\t\t\t\t\\item Biais : \\( b_3 = 0{,}60 \\)\n\t\t\t\\end{itemize}\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Fonctions d'activation :}\n\t\t\\begin{itemize}\n\t\t\t\\item Fonction sigmoïde : \\( \\sigma(z) = \\dfrac{1}{1 + e^{-z}} \\)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Fonction de coût :}\n\t\t\\begin{itemize}\n\t\t\t\\item Erreur quadratique moyenne : \\( E = \\dfrac{1}{2}(y - \\hat{y})^2 \\)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Données :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Entrée :} \\( x = 0{,}05 \\)\n\t\t\t\\item \\textbf{Sortie cible :} \\( y = 0{,}01 \\)\n\t\t\\end{itemize}\n\t\\end{itemize}",
        "html": "<p>Vous allez travailler avec un réseau de neurones à une couche cachée, conçu pour effectuer une tâche de prédiction simple.</p>\n<p><strong>Description du réseau</strong></p>\n<ul>\n<li><p><strong>Entrée :</strong></p>\n<ul>\n<li><p><span class=\"math inline\">\\(x \\in \\mathbb{R}\\)</span> (scalaire)</p></li>\n</ul></li>\n<li><p><strong>Couche cachée (2 neurones) :</strong></p>\n<ul>\n<li><p><strong>Neurone caché 1 :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_1 = 0{,}15\\)</span></p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_1 = 0{,}35\\)</span></p></li>\n</ul></li>\n<li><p><strong>Neurone caché 2 :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_2 = 0{,}20\\)</span></p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_2 = 0{,}35\\)</span></p></li>\n</ul></li>\n</ul></li>\n<li><p><strong>Couche de sortie (1 neurone) :</strong></p>\n<ul>\n<li><p><strong>Neurone de sortie :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_3 = 0{,}40\\)</span> (connecté au neurone caché 1)</p></li>\n<li><p>Poids : <span class=\"math inline\">\\(w_4 = 0{,}45\\)</span> (connecté au neurone caché 2)</p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_3 = 0{,}60\\)</span></p></li>\n</ul></li>\n</ul></li>\n<li><p><strong>Fonctions d’activation :</strong></p>\n<ul>\n<li><p>Fonction sigmoïde : <span class=\"math inline\">\\(\\sigma(z) = \\dfrac{1}{1 + e^{-z}}\\)</span></p></li>\n</ul></li>\n<li><p><strong>Fonction de coût :</strong></p>\n<ul>\n<li><p>Erreur quadratique moyenne : <span class=\"math inline\">\\(E = \\dfrac{1}{2}(y - \\hat{y})^2\\)</span></p></li>\n</ul></li>\n<li><p><strong>Données :</strong></p>\n<ul>\n<li><p><strong>Entrée :</strong> <span class=\"math inline\">\\(x = 0{,}05\\)</span></p></li>\n<li><p><strong>Sortie cible :</strong> <span class=\"math inline\">\\(y = 0{,}01\\)</span></p></li>\n</ul></li>\n</ul>\n"
      }
    },
    {
      "id": "3941aa05-8345-402f-81c8-0bec77673b55",
      "type": "question",
      "value": {
        "latex": "Calculer les sorties des neurones de la couche cachée (\\( h_1 \\) et \\( h_2 \\)).",
        "html": "<p>Calculer les sorties des neurones de la couche cachée (<span class=\"math inline\">\\(h_1\\)</span> et <span class=\"math inline\">\\(h_2\\)</span>).</p>\n"
      }
    },
    {
      "id": "b4b5661b-8000-4678-8166-72160a896fb4",
      "type": "indication",
      "value": {
        "latex": "",
        "html": "\n"
      }
    },
    {
      "id": "1466d955-8b29-4527-baf6-94e9392bd773",
      "type": "reponse",
      "value": {
        "latex": "Neurone caché 1 : \n    \t$$\\begin{align*}\n    \t\\text{Entrée nette : } & net_{h1} = w_1 \\cdot x + b_1 \\\\\n    \t& net_{h1} = 0{,}15 \\times 0{,}05 + 0{,}35 = 0{,}3575 \\\\\n    \t\\text{Sortie : } & h_1 = \\sigma(net_{h1}) = \\dfrac{1}{1 + e^{-0{,}3575}} \\approx 0{,}5889\n    \t\\end{align*}$$\n    \t\n    \t\n    \tNeurone caché 2 :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \t\\text{Entrée nette : } & net_{h2} = w_2 \\cdot x + b_2 \\\\\n    \t& net_{h2} = 0{,}20 \\times 0{,}05 + 0{,}35 = 0{,}36 \\\\\n    \t\\text{Sortie : } & h_2 = \\sigma(net_{h2}) = \\dfrac{1}{1 + e^{-0{,}36}} \\approx 0{,}5890\n    \t\\end{align*}$$",
        "html": "<p>Neurone caché 1 : <span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_{h1} = w_1 \\cdot x + b_1 \\\\\n        &amp; net_{h1} = 0{,}15 \\times 0{,}05 + 0{,}35 = 0{,}3575 \\\\\n        \\text{Sortie : } &amp; h_1 = \\sigma(net_{h1}) = \\dfrac{1}{1 + e^{-0{,}3575}} \\approx 0{,}5889\n        \\end{align*}\\]</span></p>\n<p>Neurone caché 2 :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_{h2} = w_2 \\cdot x + b_2 \\\\\n        &amp; net_{h2} = 0{,}20 \\times 0{,}05 + 0{,}35 = 0{,}36 \\\\\n        \\text{Sortie : } &amp; h_2 = \\sigma(net_{h2}) = \\dfrac{1}{1 + e^{-0{,}36}} \\approx 0{,}5890\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "6929436a-261f-4a03-82de-ffb206921269",
      "type": "question",
      "value": {
        "latex": "Calculer la sortie du neurone de sortie (\\( \\hat{y} \\)).",
        "html": "<p>Calculer la sortie du neurone de sortie (<span class=\"math inline\">\\(\\hat{y}\\)</span>).</p>\n"
      }
    },
    {
      "id": "7e8fef33-7bf8-44be-bf5e-e21942909e8a",
      "type": "indication",
      "value": {
        "latex": "",
        "html": "\n"
      }
    },
    {
      "id": "7fcc4590-385b-493f-8bc8-28f637489dca",
      "type": "reponse",
      "value": {
        "latex": "$$\\begin{align*}\n    \t\\text{Entrée nette : } & net_o = w_3 \\cdot h_1 + w_4 \\cdot h_2 + b_3 \\\\\n    \t& net_o = 0{,}40 \\times 0{,}5889 + 0{,}45 \\times 0{,}5890 + 0{,}60 \\\\\n    \t& net_o = 0{,}2356 + 0{,}2650 + 0{,}60 = 1{,}1006 \\\\\n    \t\\text{Sortie : } & \\hat{y} = \\sigma(net_o) = \\dfrac{1}{1 + e^{-1{,}1006}} \\approx 0{,}7507\n    \t\\end{align*}$$",
        "html": "<p><span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_o = w_3 \\cdot h_1 + w_4 \\cdot h_2 + b_3 \\\\\n        &amp; net_o = 0{,}40 \\times 0{,}5889 + 0{,}45 \\times 0{,}5890 + 0{,}60 \\\\\n        &amp; net_o = 0{,}2356 + 0{,}2650 + 0{,}60 = 1{,}1006 \\\\\n        \\text{Sortie : } &amp; \\hat{y} = \\sigma(net_o) = \\dfrac{1}{1 + e^{-1{,}1006}} \\approx 0{,}7507\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "0b77a658-b870-42f0-b741-0e03765b4c91",
      "type": "question",
      "value": {
        "latex": "Calculer l'erreur du réseau en utilisant la fonction de coût.",
        "html": "<p>Calculer l’erreur du réseau en utilisant la fonction de coût.</p>\n"
      }
    },
    {
      "id": "6b96d564-86e4-41cf-ba94-700c20bb135d",
      "type": "reponse",
      "value": {
        "latex": "$$\\begin{align*}\n    \tE = \\dfrac{1}{2}(y - \\hat{y})^2 = \\dfrac{1}{2}(0{,}01 - 0{,}7507)^2 = \\dfrac{1}{2}(-0{,}7407)^2 \\approx 0{,}2741\n    \t\\end{align*}$$",
        "html": "<p><span class=\"math display\">\\[\\begin{align*}\n        E = \\dfrac{1}{2}(y - \\hat{y})^2 = \\dfrac{1}{2}(0{,}01 - 0{,}7507)^2 = \\dfrac{1}{2}(-0{,}7407)^2 \\approx 0{,}2741\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "0f7fa007-bf09-4d62-8750-80229beb0f07",
      "type": "question",
      "value": {
        "latex": "Calculer les gradients des poids \\( w_3 \\) et \\( w_4 \\) de la couche de sortie  les gradients des poids \\( w_1 \\) et \\( w_2 \\) de la couche cachée.",
        "html": "<p>Calculer les gradients des poids <span class=\"math inline\">\\(w_3\\)</span> et <span class=\"math inline\">\\(w_4\\)</span> de la couche de sortie les gradients des poids <span class=\"math inline\">\\(w_1\\)</span> et <span class=\"math inline\">\\(w_2\\)</span> de la couche cachée.</p>\n"
      }
    },
    {
      "id": "3c272373-49d5-4d7e-8ebd-4c9a407a516d",
      "type": "reponse",
      "value": {
        "latex": "Calcul de l'erreur locale au neurone de sortie (\\( \\delta_o \\)) :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \t\\delta_o = \\dfrac{\\partial E}{\\partial net_o} = \\dfrac{\\partial E}{\\partial \\hat{y}} \\cdot \\dfrac{\\partial \\hat{y}}{\\partial net_o} \\\\\n    \t\\dfrac{\\partial E}{\\partial \\hat{y}} = \\hat{y} - y = 0{,}7507 - 0{,}01 = 0{,}7407 \\\\\n    \t\\dfrac{\\partial \\hat{y}}{\\partial net_o} = \\hat{y}(1 - \\hat{y}) = 0{,}7507 \\times 0{,}2493 \\approx 0{,}1875 \\\\\n    \t\\delta_o = 0{,}7407 \\times 0{,}1875 \\approx 0{,}1389\n    \t\\end{align*}$$\n    \t\n    \t\n    \tCalcul des gradients des poids :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \t\\dfrac{\\partial E}{\\partial w_3} = \\delta_o \\cdot h_1 = 0{,}1389 \\times 0{,}5889 \\approx 0{,}0817 \\\\\n    \t\\dfrac{\\partial E}{\\partial w_4} = \\delta_o \\cdot h_2 = 0{,}1389 \\times 0{,}5890 \\approx 0{,}0818\n    \t\\end{align*}$$\n    \t\n    \t\n    \tCalcul des gradients des poids \\( w_1 \\) et \\( w_2 \\)\n    \t\n    \tCalcul des erreurs locales aux neurones cachés (\\( \\delta_{h1} \\) et \\( \\delta_{h2} \\)) :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \t\\delta_{h1} = \\delta_o \\cdot w_3 \\cdot h_1 (1 - h_1) \\\\\n    \t& = 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times (1 - 0{,}5889) \\\\\n    \t& \\approx 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times 0{,}4111 \\approx 0{,}0134 \\\\\n    \t\\delta_{h2} = \\delta_o \\cdot w_4 \\cdot h_2 (1 - h_2) \\\\\n    \t& = 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times (1 - 0{,}5890) \\\\\n    \t& \\approx 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times 0{,}4110 \\approx 0{,}0150\n    \t\\end{align*}$$\n    \t\n    \t\n    \tCalcul des gradients des poids :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \t\\dfrac{\\partial E}{\\partial w_1} = \\delta_{h1} \\cdot x = 0{,}0134 \\times 0{,}05 \\approx 0{,}0007 \\\\\n    \t\\dfrac{\\partial E}{\\partial w_2} = \\delta_{h2} \\cdot x = 0{,}0150 \\times 0{,}05 \\approx 0{,}0008\n    \t\\end{align*}$$",
        "html": "<p>Calcul de l’erreur locale au neurone de sortie (<span class=\"math inline\">\\(\\delta_o\\)</span>) :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\delta_o = \\dfrac{\\partial E}{\\partial net_o} = \\dfrac{\\partial E}{\\partial \\hat{y}} \\cdot \\dfrac{\\partial \\hat{y}}{\\partial net_o} \\\\\n        \\dfrac{\\partial E}{\\partial \\hat{y}} = \\hat{y} - y = 0{,}7507 - 0{,}01 = 0{,}7407 \\\\\n        \\dfrac{\\partial \\hat{y}}{\\partial net_o} = \\hat{y}(1 - \\hat{y}) = 0{,}7507 \\times 0{,}2493 \\approx 0{,}1875 \\\\\n        \\delta_o = 0{,}7407 \\times 0{,}1875 \\approx 0{,}1389\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\dfrac{\\partial E}{\\partial w_3} = \\delta_o \\cdot h_1 = 0{,}1389 \\times 0{,}5889 \\approx 0{,}0817 \\\\\n        \\dfrac{\\partial E}{\\partial w_4} = \\delta_o \\cdot h_2 = 0{,}1389 \\times 0{,}5890 \\approx 0{,}0818\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids <span class=\"math inline\">\\(w_1\\)</span> et <span class=\"math inline\">\\(w_2\\)</span></p>\n<p>Calcul des erreurs locales aux neurones cachés (<span class=\"math inline\">\\(\\delta_{h1}\\)</span> et <span class=\"math inline\">\\(\\delta_{h2}\\)</span>) :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\delta_{h1} = \\delta_o \\cdot w_3 \\cdot h_1 (1 - h_1) \\\\\n        &amp; = 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times (1 - 0{,}5889) \\\\\n        &amp; \\approx 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times 0{,}4111 \\approx 0{,}0134 \\\\\n        \\delta_{h2} = \\delta_o \\cdot w_4 \\cdot h_2 (1 - h_2) \\\\\n        &amp; = 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times (1 - 0{,}5890) \\\\\n        &amp; \\approx 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times 0{,}4110 \\approx 0{,}0150\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\dfrac{\\partial E}{\\partial w_1} = \\delta_{h1} \\cdot x = 0{,}0134 \\times 0{,}05 \\approx 0{,}0007 \\\\\n        \\dfrac{\\partial E}{\\partial w_2} = \\delta_{h2} \\cdot x = 0{,}0150 \\times 0{,}05 \\approx 0{,}0008\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "0ac53a78-9baf-44f0-a32e-a524a99d098e",
      "type": "question",
      "value": {
        "latex": "Avec un taux d'apprentissage \\( \\eta = 0{,}5 \\), mettre à jour tous les poids du réseau.",
        "html": "<p>Avec un taux d’apprentissage <span class=\"math inline\">\\(\\eta = 0{,}5\\)</span>, mettre à jour tous les poids du réseau.</p>\n"
      }
    },
    {
      "id": "1582f4e1-c49c-404b-9ed6-58249ff41ed0",
      "type": "reponse",
      "value": {
        "latex": "Avec \\( \\eta = 0{,}5 \\) :\n    \t\n    \t- Mise à jour des poids de la couche de sortie :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \tw_3^{\\text{nouveau}} = w_3^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_3} = 0{,}40 - 0{,}5 \\times 0{,}0817 = 0{,}3592 \\\\\n    \tw_4^{\\text{nouveau}} = w_4^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_4} = 0{,}45 - 0{,}5 \\times 0{,}0818 = 0{,}4091\n    \t\\end{align*}$$\n    \t\n    \t\n    \t- Mise à jour des poids de la couche cachée :\n    \t\n    \t\n    \t$$\\begin{align*}\n    \tw_1^{\\text{nouveau}} = w_1^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_1} = 0{,}15 - 0{,}5 \\times 0{,}0007 = 0{,}1497 \\\\\n    \tw_2^{\\text{nouveau}} = w_2^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_2} = 0{,}20 - 0{,}5 \\times 0{,}0008 = 0{,}1996\n    \t\\end{align*}$$",
        "html": "<p>Avec <span class=\"math inline\">\\(\\eta = 0{,}5\\)</span> :</p>\n<p>- Mise à jour des poids de la couche de sortie :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        w_3^{\\text{nouveau}} = w_3^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_3} = 0{,}40 - 0{,}5 \\times 0{,}0817 = 0{,}3592 \\\\\n        w_4^{\\text{nouveau}} = w_4^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_4} = 0{,}45 - 0{,}5 \\times 0{,}0818 = 0{,}4091\n        \\end{align*}\\]</span></p>\n<p>- Mise à jour des poids de la couche cachée :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        w_1^{\\text{nouveau}} = w_1^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_1} = 0{,}15 - 0{,}5 \\times 0{,}0007 = 0{,}1497 \\\\\n        w_2^{\\text{nouveau}} = w_2^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_2} = 0{,}20 - 0{,}5 \\times 0{,}0008 = 0{,}1996\n        \\end{align*}\\]</span></p>\n"
      }
    }
  ]
}