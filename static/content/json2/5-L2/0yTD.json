{
  "uuid": "0yTD",
  "titre": "",
  "theme": "",
  "niveau": "",
  "metadata": {
    "exo7id": "5901",
    "auteur": "rouget",
    "createdAt": "2010-10-16",
    "hasIndication": "false",
    "hasCorrection": "true",
    "chapitre": "Fonction de plusieurs variables",
    "sousChapitre": "Continuité",
    "organisation": "",
    "updatedAt": "2025-02-10T15:44:31.933Z"
  },
  "contenu": [
    {
      "id": "277ce98d-c2f8-49f8-9b88-75d1dc19b272",
      "type": "description",
      "value": {
        "latex": "$E =\\Rr^n$ est muni de sa structure euclidienne usuelle.\nMontrer que $\\begin{array}[t]{cccc}\nf~:&E&\\rightarrow&\\Rr\\\\\n &x&\\mapsto&\\|x\\|_2\n\\end{array}$ est différentiable sur $E\\setminus\\{0\\}$ et préciser $df$. Montrer que $f$ n'est pas différentiable en $0$.",
        "html": "<p><span class=\"math inline\">\\(E =\\Rr^n\\)</span> est muni de sa structure euclidienne usuelle. Montrer que <span class=\"math inline\">\\(\\begin{array}[t]{cccc}\nf~:&amp;E&amp;\\rightarrow&amp;\\Rr\\\\\n &amp;x&amp;\\mapsto&amp;\\|x\\|_2\n\\end{array}\\)</span> est différentiable sur <span class=\"math inline\">\\(E\\setminus\\{0\\}\\)</span> et préciser <span class=\"math inline\">\\(df\\)</span>. Montrer que <span class=\"math inline\">\\(f\\)</span> n’est pas différentiable en <span class=\"math inline\">\\(0\\)</span>.</p>\n"
      }
    },
    {
      "id": "53d2402f-ef34-46d0-ae0d-b490ad32f35a",
      "type": "reponse",
      "value": {
        "latex": "\\textbf{1ère solution.} Pour $x=(x_1,\\ldots,x_n)\\in\\Rr^n$, $f(x)=\\sqrt{\\sum_{i=1}^{n}x_i^2}$. $f$ est de classe $C^1$ sur $\\Rr^n\\setminus\\{0\\}$ en vertu de théorèmes généraux et pour tout $x=(x_1,\\ldots,x_n)\\in\\Rr^n\\setminus\\{0\\}$ et tout $i\\in\\llbracket1,n\\rrbracket$\n\n\\begin{center}\n$ \\frac{\\partial f}{\\partial x_i}(x)= \\frac{x_i}{\\sqrt{\\sum_{i=1}^{n}x_i^2}}= \\frac{x_i}{\\|x\\|_2}$.\n\\end{center}\n\nOn en déduit que $f$ est différentiable sur $\\Rr^n\\setminus\\{0\\}$ et pour $x\\in\\Rr^n\\setminus\\{0\\}$ et $h\\in\\Rr^n$\n\n\\begin{center}\n$df_x(h)=\\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i}(x)h_i= \\frac{1}{\\|x\\|_2}\\sum_{i=1}^{n}x_ih_i= \\frac{x|h}{\\|x\\|_2}$.\n\\end{center}\n\n\\begin{center}\n\\shadowbox{\n$\\forall x\\in\\Rr^n\\setminus\\{0\\}$, $\\forall h\\in\\Rr^n$, $df_x(h)= \\frac{x|h}{\\|x\\|_2}$.\n}\n\\end{center}\n\n\\textbf{2 ème solution.} Soit $x\\in\\Rr^n\\setminus\\{0\\}$. Pour $h\\in\\Rr^n$,\n\n\\begin{center}\n$\\|x+h\\|_2-\\|x\\|_2= \\frac{\\left(\\|x+h\\|_2-\\|x\\|_2\\right)\\left(\\|x+h\\|_2+\\|x\\|_2\\right)}{\\|x+h\\|_2+\\|x\\|_2}= \\frac{2(x|h)+\\|h\\|_2^2}{\\|x+h\\|_2+\\|x\\|_2}$,\n\\end{center}\n\npuis\n\n\\begin{center}\n$\\|x+h\\|_2-\\|x\\|_2- \\frac{x|h}{\\|x\\|_2}= \\frac{2(x|h)+\\|h\\|_2^2}{\\|x+h\\|_2+\\|x\\|_2}- \\frac{x|h}{\\|x\\|_2}= \\frac{-\\left(\\|x+h\\|_2-\\|x\\|_2\\right)(x|h)+\\|x\\|_2\\|h\\|_2^2}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}$.\n\\end{center}\n\nMaintenant, on sait que l'application $x\\mapsto\\|x\\|_2$ est continue sur $\\Rr^n$. On en déduit que $ \\frac{1}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}\\underset{h\\rightarrow0}{\\sim} \\frac{1}{2\\|x\\|_2^2}$ et aussi que $\\|x+h\\|_2-\\|x\\|_2$ tend vers $0$ quand $h$ tend vers $0$. Ensuite, puisque $\\left|(x|h)\\right|\\leqslant\\|x\\|_2\\|h\\|_2$ (inégalité de \\textsc{Cauchy}-\\textsc{Schwarz}), on a $x|h\\underset{h\\rightarrow0}{=}O(\\|h\\|_2)$ puis $\\left(\\|x+h\\|_2-\\|x\\|_2\\right)\\left(x|h\\right)\\underset{h\\rightarrow0}{=}o(\\|h\\|_2)$.\n\nFinalement, $ \\frac{-\\left(\\|x+h\\|_2-\\|x\\|_2\\right)(x|h)+\\|x\\|_2\\|h\\|_2^2}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}\\underset{h\\rightarrow0}{=}o(\\|h\\|_2)$ et donc\n\n\\begin{center}\n$\\|x+h\\|_2\\underset{h\\rightarrow0}{=}\\|x\\|_2+ \\frac{x|h}{\\|x\\|_2}+o(\\|h\\|_2)$.\n\\end{center}\n\nPuisque l'application $h\\mapsto \\frac{x|h}{\\|x\\|_2}$ est linéaire, on a redémontré que $f$ est différentiable en tout $x$ de $\\Rr^n\\setminus\\{0\\}$ et que $\\forall x\\in\\Rr^n\\setminus\\{0\\}$, $\\forall h\\in\\Rr^n$, $df_x(h)= \\frac{x|h}{\\|x\\|_2}$.\n\nSoit $L$ une application linéaire de $\\Rr^n$ dans $\\Rr$ c'est-à-dire une forme linéaire.\n\n\\begin{center}\n$ \\frac{1}{\\|h\\|_2}\\left(\\|0+h\\|_2-\\|0\\|_2-L(h)\\right)=1-L\\left( \\frac{h}{\\|h\\|_2}\\right)$.\n\\end{center}\n\nSupposons que cette expression tende vers $0$ quand $h$ tend vers $0$. Pour $u$ vecteur non nul donné et $t$ réel non nul, l'expression $1-L\\left( \\frac{tu}{\\|tu\\|_2}\\right)=1- \\frac{t}{|t|}L\\left( \\frac{u}{\\|u\\|_2}\\right)$ tend donc vers $0$ quand $t$ tend vers $0$. Mais si $t$ tend vers $0$ par valeurs supérieures, on obtient $L(u)=\\|u\\|_2$ et si $t$ tend vers $0$ par valeurs inférieures, on obtient $L(u)=-\\|u\\|_2$ ce qui est impossible car $u\\neq0$. Donc $f$ n'est pas différentiable en $0$.",
        "html": "<p><strong>1ère solution.</strong> Pour <span class=\"math inline\">\\(x=(x_1,\\ldots,x_n)\\in\\Rr^n\\)</span>, <span class=\"math inline\">\\(f(x)=\\sqrt{\\sum_{i=1}^{n}x_i^2}\\)</span>. <span class=\"math inline\">\\(f\\)</span> est de classe <span class=\"math inline\">\\(C^1\\)</span> sur <span class=\"math inline\">\\(\\Rr^n\\setminus\\{0\\}\\)</span> en vertu de théorèmes généraux et pour tout <span class=\"math inline\">\\(x=(x_1,\\ldots,x_n)\\in\\Rr^n\\setminus\\{0\\}\\)</span> et tout <span class=\"math inline\">\\(i\\in\\llbracket1,n\\rrbracket\\)</span></p>\n<p><span class=\"math inline\">\\(\\frac{\\partial f}{\\partial x_i}(x)= \\frac{x_i}{\\sqrt{\\sum_{i=1}^{n}x_i^2}}= \\frac{x_i}{\\|x\\|_2}\\)</span>.</p>\n<p>On en déduit que <span class=\"math inline\">\\(f\\)</span> est différentiable sur <span class=\"math inline\">\\(\\Rr^n\\setminus\\{0\\}\\)</span> et pour <span class=\"math inline\">\\(x\\in\\Rr^n\\setminus\\{0\\}\\)</span> et <span class=\"math inline\">\\(h\\in\\Rr^n\\)</span></p>\n<p><span class=\"math inline\">\\(df_x(h)=\\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i}(x)h_i= \\frac{1}{\\|x\\|_2}\\sum_{i=1}^{n}x_ih_i= \\frac{x|h}{\\|x\\|_2}\\)</span>.</p>\n<p><strong>2 ème solution.</strong> Soit <span class=\"math inline\">\\(x\\in\\Rr^n\\setminus\\{0\\}\\)</span>. Pour <span class=\"math inline\">\\(h\\in\\Rr^n\\)</span>,</p>\n<p><span class=\"math inline\">\\(\\|x+h\\|_2-\\|x\\|_2= \\frac{\\left(\\|x+h\\|_2-\\|x\\|_2\\right)\\left(\\|x+h\\|_2+\\|x\\|_2\\right)}{\\|x+h\\|_2+\\|x\\|_2}= \\frac{2(x|h)+\\|h\\|_2^2}{\\|x+h\\|_2+\\|x\\|_2}\\)</span>,</p>\n<p>puis</p>\n<p><span class=\"math inline\">\\(\\|x+h\\|_2-\\|x\\|_2- \\frac{x|h}{\\|x\\|_2}= \\frac{2(x|h)+\\|h\\|_2^2}{\\|x+h\\|_2+\\|x\\|_2}- \\frac{x|h}{\\|x\\|_2}= \\frac{-\\left(\\|x+h\\|_2-\\|x\\|_2\\right)(x|h)+\\|x\\|_2\\|h\\|_2^2}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}\\)</span>.</p>\n<p>Maintenant, on sait que l’application <span class=\"math inline\">\\(x\\mapsto\\|x\\|_2\\)</span> est continue sur <span class=\"math inline\">\\(\\Rr^n\\)</span>. On en déduit que <span class=\"math inline\">\\(\\frac{1}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}\\underset{h\\rightarrow0}{\\sim} \\frac{1}{2\\|x\\|_2^2}\\)</span> et aussi que <span class=\"math inline\">\\(\\|x+h\\|_2-\\|x\\|_2\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span> quand <span class=\"math inline\">\\(h\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span>. Ensuite, puisque <span class=\"math inline\">\\(\\left|(x|h)\\right|\\leqslant\\|x\\|_2\\|h\\|_2\\)</span> (inégalité de <span class=\"smallcaps\">Cauchy</span>-<span class=\"smallcaps\">Schwarz</span>), on a <span class=\"math inline\">\\(x|h\\underset{h\\rightarrow0}{=}O(\\|h\\|_2)\\)</span> puis <span class=\"math inline\">\\(\\left(\\|x+h\\|_2-\\|x\\|_2\\right)\\left(x|h\\right)\\underset{h\\rightarrow0}{=}o(\\|h\\|_2)\\)</span>.</p>\n<p>Finalement, <span class=\"math inline\">\\(\\frac{-\\left(\\|x+h\\|_2-\\|x\\|_2\\right)(x|h)+\\|x\\|_2\\|h\\|_2^2}{\\left(\\|x+h\\|_2+\\|x\\|_2\\right)\\|x\\|_2}\\underset{h\\rightarrow0}{=}o(\\|h\\|_2)\\)</span> et donc</p>\n<p><span class=\"math inline\">\\(\\|x+h\\|_2\\underset{h\\rightarrow0}{=}\\|x\\|_2+ \\frac{x|h}{\\|x\\|_2}+o(\\|h\\|_2)\\)</span>.</p>\n<p>Puisque l’application <span class=\"math inline\">\\(h\\mapsto \\frac{x|h}{\\|x\\|_2}\\)</span> est linéaire, on a redémontré que <span class=\"math inline\">\\(f\\)</span> est différentiable en tout <span class=\"math inline\">\\(x\\)</span> de <span class=\"math inline\">\\(\\Rr^n\\setminus\\{0\\}\\)</span> et que <span class=\"math inline\">\\(\\forall x\\in\\Rr^n\\setminus\\{0\\}\\)</span>, <span class=\"math inline\">\\(\\forall h\\in\\Rr^n\\)</span>, <span class=\"math inline\">\\(df_x(h)= \\frac{x|h}{\\|x\\|_2}\\)</span>.</p>\n<p>Soit <span class=\"math inline\">\\(L\\)</span> une application linéaire de <span class=\"math inline\">\\(\\Rr^n\\)</span> dans <span class=\"math inline\">\\(\\Rr\\)</span> c’est-à-dire une forme linéaire.</p>\n<p><span class=\"math inline\">\\(\\frac{1}{\\|h\\|_2}\\left(\\|0+h\\|_2-\\|0\\|_2-L(h)\\right)=1-L\\left( \\frac{h}{\\|h\\|_2}\\right)\\)</span>.</p>\n<p>Supposons que cette expression tende vers <span class=\"math inline\">\\(0\\)</span> quand <span class=\"math inline\">\\(h\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span>. Pour <span class=\"math inline\">\\(u\\)</span> vecteur non nul donné et <span class=\"math inline\">\\(t\\)</span> réel non nul, l’expression <span class=\"math inline\">\\(1-L\\left( \\frac{tu}{\\|tu\\|_2}\\right)=1- \\frac{t}{|t|}L\\left( \\frac{u}{\\|u\\|_2}\\right)\\)</span> tend donc vers <span class=\"math inline\">\\(0\\)</span> quand <span class=\"math inline\">\\(t\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span>. Mais si <span class=\"math inline\">\\(t\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span> par valeurs supérieures, on obtient <span class=\"math inline\">\\(L(u)=\\|u\\|_2\\)</span> et si <span class=\"math inline\">\\(t\\)</span> tend vers <span class=\"math inline\">\\(0\\)</span> par valeurs inférieures, on obtient <span class=\"math inline\">\\(L(u)=-\\|u\\|_2\\)</span> ce qui est impossible car <span class=\"math inline\">\\(u\\neq0\\)</span>. Donc <span class=\"math inline\">\\(f\\)</span> n’est pas différentiable en <span class=\"math inline\">\\(0\\)</span>.</p>\n"
      }
    }
  ]
}