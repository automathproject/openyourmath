{
  "uuid": "w4TW",
  "titre": "Maximum de vraisemblance",
  "theme": [
    "statistiques"
  ],
  "niveau": "",
  "metadata": {
    "auteur": "",
    "createdAt": "2024-12-05T15:38:07.309Z",
    "organisation": "",
    "updatedAt": "2024-12-05T15:38:07.309Z"
  },
  "contenu": [
    {
      "id": "f247270d-d405-4dc0-8107-86181957a06a",
      "type": "description",
      "value": {
        "latex": "On considère une variable aléatoire $X$ suivant une loi exponentielle de paramètre $\\theta > 0$. On rappelle que sa densité est donnée par :\n$$f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x} & \\text{ si } x \\geq 0 \\\\ 0 & \\text{ sinon. } \\end{cases}$$\nOn dispose d'un échantillon $(X_1,...,X_n)$ de $n$ variables aléatoires indépendantes et de même loi que $X$. On cherche à estimer le paramètre $\\theta$ par la méthode du maximum de vraisemblance.",
        "html": "<p>On considère une variable aléatoire <span class=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de paramètre <span class=\"math inline\">\\(\\theta &gt; 0\\)</span>. On rappelle que sa densité est donnée par : <span class=\"math display\">\\[f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x} &amp; \\text{ si } x \\geq 0 \\\\ 0 &amp; \\text{ sinon. } \\end{cases}\\]</span> On dispose d’un échantillon <span class=\"math inline\">\\((X_1,...,X_n)\\)</span> de <span class=\"math inline\">\\(n\\)</span> variables aléatoires indépendantes et de même loi que <span class=\"math inline\">\\(X\\)</span>. On cherche à estimer le paramètre <span class=\"math inline\">\\(\\theta\\)</span> par la méthode du maximum de vraisemblance.</p>\n"
      }
    },
    {
      "id": "1fe13c7e-51dd-49ba-a9f8-7dc5cc56b050",
      "type": "question",
      "value": {
        "latex": "Écrire la vraisemblance $L(\\theta)$ de l'échantillon en fonction de $\\theta$ et des observations $(x_1,...,x_n)$.",
        "html": "<p>Écrire la vraisemblance <span class=\"math inline\">\\(L(\\theta)\\)</span> de l’échantillon en fonction de <span class=\"math inline\">\\(\\theta\\)</span> et des observations <span class=\"math inline\">\\((x_1,...,x_n)\\)</span>.</p>\n"
      }
    },
    {
      "id": "298611ee-a92d-4bef-bc22-da37be9c758b",
      "type": "reponse",
      "value": {
        "latex": "Par indépendance des variables, la vraisemblance est le produit des densités :\n        $$\\begin{align*}\n            L(\\theta) &= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i \\geq 0} \\\\\n            &= \\theta^n e^{-\\theta \\sum_{i=1}^n x_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}$$",
        "html": "<p>Par indépendance des variables, la vraisemblance est le produit des densités : <span class=\"math display\">\\[\\begin{align*}\n            L(\\theta) &amp;= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &amp;= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i \\geq 0} \\\\\n            &amp;= \\theta^n e^{-\\theta \\sum_{i=1}^n x_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "19cefec2-33c7-4a98-801e-e0f84a7f7404",
      "type": "question",
      "value": {
        "latex": "En déduire la log-vraisemblance $\\ell(\\theta)$ puis calculer sa dérivée $\\ell'(\\theta)$.",
        "html": "<p>En déduire la log-vraisemblance <span class=\"math inline\">\\(\\ell(\\theta)\\)</span> puis calculer sa dérivée <span class=\"math inline\">\\(\\ell&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "69bc7ca6-ba76-4d03-b50e-a5a6046dd530",
      "type": "reponse",
      "value": {
        "latex": "La log-vraisemblance est :\n        $$\\begin{align*}\n            \\ell(\\theta) &= \\ln(L(\\theta)) \\\\\n            &= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}$$\n        \n        Sa dérivée est :\n        $$\\ell'(\\theta) = \\frac{n}{\\theta} - \\sum_{i=1}^n x_i$$",
        "html": "<p>La log-vraisemblance est : <span class=\"math display\">\\[\\begin{align*}\n            \\ell(\\theta) &amp;= \\ln(L(\\theta)) \\\\\n            &amp;= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}\\]</span></p>\n<p>Sa dérivée est : <span class=\"math display\">\\[\\ell&#39;(\\theta) = \\frac{n}{\\theta} - \\sum_{i=1}^n x_i\\]</span></p>\n"
      }
    },
    {
      "id": "c73bccba-a18a-4a83-bceb-ba69ba88c2b8",
      "type": "question",
      "value": {
        "latex": "En déduire  l'estimateur du maximum de vraisemblance $\\widehat{\\theta}_n$ de $\\theta$.",
        "html": "<p>En déduire l’estimateur du maximum de vraisemblance <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> de <span class=\"math inline\">\\(\\theta\\)</span>.</p>\n"
      }
    },
    {
      "id": "4a17a28b-d91f-4fc2-b773-10306826dbf6",
      "type": "reponse",
      "value": {
        "latex": "L'équation $\\ell'(\\theta)=0$ donne :\n        $$\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &= 0 \\\\\n            \\frac{n}{\\theta} &= \\sum_{i=1}^n x_i \\\\\n            \\theta &= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}$$\n\n        Donc $\\widehat{\\theta}_n = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}$ où $\\overline{X_n}$ est la moyenne empirique.",
        "html": "<p>L’équation <span class=\"math inline\">\\(\\ell&#39;(\\theta)=0\\)</span> donne : <span class=\"math display\">\\[\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &amp;= 0 \\\\\n            \\frac{n}{\\theta} &amp;= \\sum_{i=1}^n x_i \\\\\n            \\theta &amp;= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}\\]</span></p>\n<p>Donc <span class=\"math inline\">\\(\\widehat{\\theta}_n = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}\\)</span> où <span class=\"math inline\">\\(\\overline{X_n}\\)</span> est la moyenne empirique.</p>\n"
      }
    },
    {
      "id": "53a24cbb-fc40-4602-b47f-43ac09e56368",
      "type": "question",
      "value": {
        "latex": "Vérifier que $\\widehat{\\theta}_n$ est bien un maximum en étudiant le signe de $\\ell''(\\theta)$.",
        "html": "<p>Vérifier que <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> est bien un maximum en étudiant le signe de <span class=\"math inline\">\\(\\ell&#39;&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "7dddbb42-264d-4984-8daa-63e543e35bf6",
      "type": "reponse",
      "value": {
        "latex": "On calcule la dérivée seconde :\n        $$\\ell''(\\theta) = -\\frac{n}{\\theta^2}$$\n        \n        Cette dérivée seconde est toujours négative pour $\\theta > 0$, donc $\\widehat{\\theta}_n$ correspond bien à un maximum.",
        "html": "<p>On calcule la dérivée seconde : <span class=\"math display\">\\[\\ell&#39;&#39;(\\theta) = -\\frac{n}{\\theta^2}\\]</span></p>\n<p>Cette dérivée seconde est toujours négative pour <span class=\"math inline\">\\(\\theta &gt; 0\\)</span>, donc <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> correspond bien à un maximum.</p>\n"
      }
    },
    {
      "id": "62fccccd-f99a-432d-ab29-b47a8358c862",
      "type": "question",
      "value": {
        "latex": "Montrer que $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>Montrer que <span class=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un estimateur sans biais de <span class=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    },
    {
      "id": "70ffd712-7196-4831-aeef-2782fcf7f873",
      "type": "reponse",
      "value": {
        "latex": "On a :\n        $$\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &= \\E\\left(\\overline{X_n}\\right) \\\\\n            &= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &= \\frac{1}{\\theta}\n        \\end{align*}$$\n        \n        Donc $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>On a : <span class=\"math display\">\\[\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &amp;= \\E\\left(\\overline{X_n}\\right) \\\\\n            &amp;= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &amp;= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &amp;= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &amp;= \\frac{1}{\\theta}\n        \\end{align*}\\]</span></p>\n<p>Donc <span class=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un estimateur sans biais de <span class=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    }
  ]
}