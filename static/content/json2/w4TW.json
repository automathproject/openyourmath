{
  "uuid": "f57db05b-bfbc-4c2d-a20b-159c2fb2328b",
  "titre": "Maximum de vraisemblance",
  "theme": [
    "statistiques"
  ],
  "niveau": "",
  "metadata": {
    "auteur": "",
    "createdAt": "2024-11-05T19:10:42.406Z",
    "organisation": "",
    "updatedAt": "2024-11-05T19:10:42.406Z"
  },
  "contenu": [
    {
      "id": "207f0256-249e-4e6c-acdf-7bcf7f60fad3",
      "type": "description",
      "value": {
        "latex": "On considère une variable aléatoire $X$ suivant une loi exponentielle de paramètre $\\theta > 0$. On rappelle que sa densité est donnée par :\n$$f_\\theta(x) = \\theta e^{-\\theta x}\\mathbf{1}_{x \\geq 0}$$\nOn dispose d'un échantillon $(X_1,...,X_n)$ de $n$ variables aléatoires indépendantes et de même loi que $X$. On cherche à estimer le paramètre $\\theta$ par la méthode du maximum de vraisemblance.",
        "html": "<p>On considère une variable aléatoire <span\nclass=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de\nparamètre <span class=\"math inline\">\\(\\theta &gt; 0\\)</span>. On\nrappelle que sa densité est donnée par : <span\nclass=\"math display\">\\[f_\\theta(x) = \\theta e^{-\\theta x}\\mathbf{1}_{x\n\\geq 0}\\]</span> On dispose d’un échantillon <span\nclass=\"math inline\">\\((X_1,...,X_n)\\)</span> de <span\nclass=\"math inline\">\\(n\\)</span> variables aléatoires indépendantes et\nde même loi que <span class=\"math inline\">\\(X\\)</span>. On cherche à\nestimer le paramètre <span class=\"math inline\">\\(\\theta\\)</span> par la\nméthode du maximum de vraisemblance.</p>\n"
      }
    },
    {
      "id": "4230fccc-96c7-4cb1-97b7-281ea914afbf",
      "type": "question",
      "value": {
        "latex": "Écrire la vraisemblance $L(\\theta)$ de l'échantillon en fonction de $\\theta$ et des observations $(x_1,...,x_n)$.",
        "html": "<p>Écrire la vraisemblance <span\nclass=\"math inline\">\\(L(\\theta)\\)</span> de l’échantillon en fonction de\n<span class=\"math inline\">\\(\\theta\\)</span> et des observations <span\nclass=\"math inline\">\\((x_1,...,x_n)\\)</span>.</p>\n"
      }
    },
    {
      "id": "681bf8c7-89ef-4696-be08-f51b17806ad3",
      "type": "reponse",
      "value": {
        "latex": "Par indépendance des variables, la vraisemblance est le produit des densités :\n        $$\\begin{align*}\n            L(\\theta) &= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i \\geq 0} \\\\\n            &= \\theta^n e^{-\\theta \\sum_{i=1}^n x_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}$$",
        "html": "<p>Par indépendance des variables, la vraisemblance est le produit des\ndensités : <span class=\"math display\">\\[\\begin{align*}\n            L(\\theta) &amp;= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &amp;= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i\n\\geq 0} \\\\\n            &amp;= \\theta^n e^{-\\theta \\sum_{i=1}^n\nx_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "d888ce4a-6249-47ec-8041-1461a64a2e85",
      "type": "question",
      "value": {
        "latex": "En déduire la log-vraisemblance $\\ell(\\theta)$ puis calculer sa dérivée $\\ell'(\\theta)$.",
        "html": "<p>En déduire la log-vraisemblance <span\nclass=\"math inline\">\\(\\ell(\\theta)\\)</span> puis calculer sa dérivée\n<span class=\"math inline\">\\(\\ell&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "355631fe-cd2b-4e32-9646-b6d0e2db4122",
      "type": "reponse",
      "value": {
        "latex": "La log-vraisemblance est :\n        $$\\begin{align*}\n            \\ell(\\theta) &= \\ln(L(\\theta)) \\\\\n            &= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}$$\n        \n        Sa dérivée est :\n        $$\\ell'(\\theta) = \\frac{n}{\\theta} - \\sum_{i=1}^n x_i$$",
        "html": "<p>La log-vraisemblance est : <span\nclass=\"math display\">\\[\\begin{align*}\n            \\ell(\\theta) &amp;= \\ln(L(\\theta)) \\\\\n            &amp;= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}\\]</span></p>\n<p>Sa dérivée est : <span class=\"math display\">\\[\\ell&#39;(\\theta) =\n\\frac{n}{\\theta} - \\sum_{i=1}^n x_i\\]</span></p>\n"
      }
    },
    {
      "id": "b1f8a8dc-214c-439c-98fc-91b00865a249",
      "type": "question",
      "value": {
        "latex": "En déduire  l'estimateur du maximum de vraisemblance $\\widehat{\\theta}_n$ de $\\theta$.",
        "html": "<p>En déduire l’estimateur du maximum de vraisemblance <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> de <span\nclass=\"math inline\">\\(\\theta\\)</span>.</p>\n"
      }
    },
    {
      "id": "04eb21b6-03de-465a-83d1-575c6daf2690",
      "type": "reponse",
      "value": {
        "latex": "L'équation $\\ell'(\\theta)=0$ donne :\n        $$\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &= 0 \\\\\n            \\frac{n}{\\theta} &= \\sum_{i=1}^n x_i \\\\\n            \\theta &= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}$$\n\n        Donc $\\widehat{\\theta}_n = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}$ où $\\overline{X_n}$ est la moyenne empirique.",
        "html": "<p>L’équation <span class=\"math inline\">\\(\\ell&#39;(\\theta)=0\\)</span>\ndonne : <span class=\"math display\">\\[\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &amp;= 0 \\\\\n            \\frac{n}{\\theta} &amp;= \\sum_{i=1}^n x_i \\\\\n            \\theta &amp;= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}\\]</span></p>\n<p>Donc <span class=\"math inline\">\\(\\widehat{\\theta}_n =\n\\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}\\)</span> où <span\nclass=\"math inline\">\\(\\overline{X_n}\\)</span> est la moyenne\nempirique.</p>\n"
      }
    },
    {
      "id": "8147f8eb-7525-4da8-96b5-daed189005a8",
      "type": "question",
      "value": {
        "latex": "Vérifier que $\\widehat{\\theta}_n$ est bien un maximum en étudiant le signe de $\\ell''(\\theta)$.",
        "html": "<p>Vérifier que <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span>\nest bien un maximum en étudiant le signe de <span\nclass=\"math inline\">\\(\\ell&#39;&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "6d1331e9-a9b3-4e55-8a9d-e09d5e5dccb9",
      "type": "reponse",
      "value": {
        "latex": "On calcule la dérivée seconde :\n        $$\\ell''(\\theta) = -\\frac{n}{\\theta^2}$$\n        \n        Cette dérivée seconde est toujours négative pour $\\theta > 0$, donc $\\widehat{\\theta}_n$ correspond bien à un maximum.",
        "html": "<p>On calcule la dérivée seconde : <span\nclass=\"math display\">\\[\\ell&#39;&#39;(\\theta) =\n-\\frac{n}{\\theta^2}\\]</span></p>\n<p>Cette dérivée seconde est toujours négative pour <span\nclass=\"math inline\">\\(\\theta &gt; 0\\)</span>, donc <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> correspond bien à un\nmaximum.</p>\n"
      }
    },
    {
      "id": "8165ab7a-afae-4ccf-8c60-e8f72019d12f",
      "type": "question",
      "value": {
        "latex": "Montrer que $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>Montrer que <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    },
    {
      "id": "d4de5a75-19d1-4004-ba46-442c02438adc",
      "type": "reponse",
      "value": {
        "latex": "On a :\n        $$\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &= \\E\\left(\\overline{X_n}\\right) \\\\\n            &= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &= \\frac{1}{\\theta}\n        \\end{align*}$$\n        \n        Donc $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>On a : <span class=\"math display\">\\[\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &amp;=\n\\E\\left(\\overline{X_n}\\right) \\\\\n            &amp;= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &amp;= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &amp;= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &amp;= \\frac{1}{\\theta}\n        \\end{align*}\\]</span></p>\n<p>Donc <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    }
  ]
}