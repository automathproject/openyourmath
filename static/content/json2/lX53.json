{
  "uuid": "lX53",
  "titre": "Loi géométrique et estimation par maximum de vraisemblance",
  "theme": [
    "probabilités"
  ],
  "niveau": "",
  "metadata": {
    "auteur": "",
    "createdAt": "2024-11-06T20:22:42.880Z",
    "organisation": "AMSCC",
    "updatedAt": "2024-11-06T20:22:42.880Z"
  },
  "contenu": [
    {
      "id": "b4a6f7e4-7113-4d8e-89c7-cc7a9bbef7aa",
      "type": "description",
      "value": {
        "latex": "On fixe un réel $a>0$ et on définit une variable aléatoire $X$ sur $\\mathbb{N}$ dont la loi de probabilité est définie par \n\t$$\\PP(X=k)=\\frac{a^k}{(1+a)^{k+1}}$$\n\tpour tout $k \\in \\mathbb{N}$.",
        "html": "<p>On fixe un réel <span class=\"math inline\">\\(a&gt;0\\)</span> et on\ndéfinit une variable aléatoire <span class=\"math inline\">\\(X\\)</span>\nsur <span class=\"math inline\">\\(\\mathbb{N}\\)</span> dont la loi de\nprobabilité est définie par <span\nclass=\"math display\">\\[\\PP(X=k)=\\frac{a^k}{(1+a)^{k+1}}\\]</span> pour\ntout <span class=\"math inline\">\\(k \\in \\mathbb{N}\\)</span>.</p>\n"
      }
    },
    {
      "id": "2287c30a-f371-444e-98a6-242591272462",
      "type": "question",
      "value": {
        "latex": "\\'A l'aide de la méthode du maximum de vraisemblance, définir un estimateur de $a$ et déterminer son biais.",
        "html": "<p>Á l’aide de la méthode du maximum de vraisemblance, définir un\nestimateur de <span class=\"math inline\">\\(a\\)</span> et déterminer son\nbiais.</p>\n"
      }
    },
    {
      "id": "6878fe8f-f093-415c-bc61-6d9fddc80619",
      "type": "reponse",
      "value": {
        "latex": "On définit un échantillon $X_1,...,X_n$ et on considère la probabilité que cet échantillon réalise un ensemble de valeurs $V=\\{x_1,...,x_n\\}$. La fonction de vraisemblance s'écrit alors \n\t$$L(x_1,...,x_n,a) = \\PP(X_1=x_1,...,X_n=x_n) = \\prod_{k=1}^{n} \\PP(X=x_k) = \\prod_{k=1}^n \\frac{a^{x_k}}{(1+a)^{x_k+1}} = \\frac{a^{\\sum x_k}}{(1+a)^{\\sum x_k+1}}$$\n\t\n\tOn dérive ce quotient par rapport à $a$, on factorise par $a^{\\sum x_k-1}(1+a)^{n+\\sum x_k -1}$ et on trouve que \n\t$$\\frac{\\partial L}{\\partial a}(x_1,...,x_n,a) = 0 \\iff \\sum_{k=0}^n x_k(1+a) - a(n+\\sum_{k=0}^n x_k) = 0 \\iff a = \\frac{1}{n} \\sum_{k=0}^n x_k$$\n\t\n\tOn a donc trouvé un meilleur estimateur du paramètre $a$ selon la méthode du maximum de vraisemblance : il s'agit de l'estimateur $T = \\frac{1}{n} \\sum_{k=0}^n X_k$.\n\t\n\tReste à calculer le biais de cet estimateur, autrement dit à calculer $B(T) = \\mathbb{E}(T-a)$. Or pour tout entier $i$, $X_i$ suit la loi définie ci-dessus et on espérance se calcule de la manière suivante :\n\t$$\\mathbb{E}(X_i) = \\sum_{k=0}^n k\\PP(X_i=k) = \\sum_{k=0}^n k \\left( \\frac{a}{1+a}  \\right)^{k-1} \\frac{a}{(1+a)^2} = \\frac{1}{\\left(1-\\frac{a}{1+a}\\right)^2} \\times \\frac{a}{(1+a)^2} = a$$\n\tDonc $B(T) = \\frac{1}{n} \\times n \\times a - a = 0$ : la variable $T$ est donc un estimateur sans biais du paramètre $a$.",
        "html": "<p>On définit un échantillon <span\nclass=\"math inline\">\\(X_1,...,X_n\\)</span> et on considère la\nprobabilité que cet échantillon réalise un ensemble de valeurs <span\nclass=\"math inline\">\\(V=\\{x_1,...,x_n\\}\\)</span>. La fonction de\nvraisemblance s’écrit alors <span\nclass=\"math display\">\\[L(x_1,...,x_n,a) = \\PP(X_1=x_1,...,X_n=x_n) =\n\\prod_{k=1}^{n} \\PP(X=x_k) = \\prod_{k=1}^n \\frac{a^{x_k}}{(1+a)^{x_k+1}}\n= \\frac{a^{\\sum x_k}}{(1+a)^{\\sum x_k+1}}\\]</span></p>\n<p>On dérive ce quotient par rapport à <span\nclass=\"math inline\">\\(a\\)</span>, on factorise par <span\nclass=\"math inline\">\\(a^{\\sum x_k-1}(1+a)^{n+\\sum x_k -1}\\)</span> et on\ntrouve que <span class=\"math display\">\\[\\frac{\\partial L}{\\partial\na}(x_1,...,x_n,a) = 0 \\iff \\sum_{k=0}^n x_k(1+a) - a(n+\\sum_{k=0}^n x_k)\n= 0 \\iff a = \\frac{1}{n} \\sum_{k=0}^n x_k\\]</span></p>\n<p>On a donc trouvé un meilleur estimateur du paramètre <span\nclass=\"math inline\">\\(a\\)</span> selon la méthode du maximum de\nvraisemblance : il s’agit de l’estimateur <span class=\"math inline\">\\(T\n= \\frac{1}{n} \\sum_{k=0}^n X_k\\)</span>.</p>\n<p>Reste à calculer le biais de cet estimateur, autrement dit à calculer\n<span class=\"math inline\">\\(B(T) = \\mathbb{E}(T-a)\\)</span>. Or pour\ntout entier <span class=\"math inline\">\\(i\\)</span>, <span\nclass=\"math inline\">\\(X_i\\)</span> suit la loi définie ci-dessus et on\nespérance se calcule de la manière suivante : <span\nclass=\"math display\">\\[\\mathbb{E}(X_i) = \\sum_{k=0}^n k\\PP(X_i=k) =\n\\sum_{k=0}^n k \\left( \\frac{a}{1+a}  \\right)^{k-1} \\frac{a}{(1+a)^2} =\n\\frac{1}{\\left(1-\\frac{a}{1+a}\\right)^2} \\times \\frac{a}{(1+a)^2} =\na\\]</span> Donc <span class=\"math inline\">\\(B(T) = \\frac{1}{n} \\times n\n\\times a - a = 0\\)</span> : la variable <span\nclass=\"math inline\">\\(T\\)</span> est donc un estimateur sans biais du\nparamètre <span class=\"math inline\">\\(a\\)</span>.</p>\n"
      }
    }
  ]
}