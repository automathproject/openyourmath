{
  "uuid": "aRzj",
  "titre": "Recherche d'un estimateur",
  "theme": [
    "probabilités"
  ],
  "niveau": "",
  "metadata": {
    "auteur": "",
    "createdAt": "2024-11-23T17:27:39.648Z",
    "organisation": "AMSCC",
    "updatedAt": "2024-11-23T17:27:39.648Z"
  },
  "contenu": [
    {
      "id": "18246db9-f990-4a52-895e-4d18e4aa9348",
      "type": "description",
      "value": {
        "latex": "Soient $\\theta$ un réel strictement positif et $X_1, X_2, \\ldots, X_n$ un échantillon dont la loi mère a pour densité la fonction $f$ définie sur $\\R$ par : $$f \\colon x \\mapsto \\frac{1}{\\theta^2} x e^{-\\frac{x}{\\theta}} {\\textbf{1}}_{]0;+\\infty[}(x)$$.",
        "html": "<p>Soient <span class=\"math inline\">\\(\\theta\\)</span> un réel\nstrictement positif et <span class=\"math inline\">\\(X_1, X_2, \\ldots,\nX_n\\)</span> un échantillon dont la loi mère a pour densité la fonction\n<span class=\"math inline\">\\(f\\)</span> définie sur <span\nclass=\"math inline\">\\(\\R\\)</span> par : <span class=\"math display\">\\[f\n\\colon x \\mapsto \\frac{1}{\\theta^2} x e^{-\\frac{x}{\\theta}}\n{\\textbf{1}}_{]0;+\\infty[}(x)\\]</span>.</p>\n"
      }
    },
    {
      "id": "0694af36-93af-4547-80aa-ce16d7199399",
      "type": "question",
      "value": {
        "latex": "Déterminer un estimateur de $\\theta$ issu de la méthode du maximum de vraisemblance.",
        "html": "<p>Déterminer un estimateur de <span\nclass=\"math inline\">\\(\\theta\\)</span> issu de la méthode du maximum de\nvraisemblance.</p>\n"
      }
    },
    {
      "id": "d3fc2b44-8be0-4e85-9f95-9cf15218d42d",
      "type": "reponse",
      "value": {
        "latex": "On définit un échantillon $(X_1,...,X_n)$ de cette loi et on considère une réalisation quelconque $(x_1,...,x_n)$ de cet échantillon. Le support de la loi étant l'intervalle $]0;+\\infty[$, on peut supposer que pour tout $i$, $x_i > 0$. \n\t\t\n\t\tOn exprime maintenant la log vraisemblance de cet échantillon : \n\t\t$$\\begin{align*}\n\t\t\\ln \\mathcal{L}(x_1,...,x_n,\\theta) &= \\ln \\prod_{i=1}^n f(x_i) \\\\\n\t\t&= -2n \\ln(\\theta) + \\sum_{i=1}^{n} \\ln(x_i) -\\frac{1}{\\theta} \\sum_{i=1}^{n} x_i \\\\\n\t\t\\frac{\\partial \\ln \\mathcal{L}}{\\partial \\theta}(x_1,...,x_n,\\theta) = 0 &\\iff \\theta = \\frac{1}{2 n} \\sum_{i=1}^n x_i \\\\\n\t\t\\frac{\\partial^2 \\ln \\mathcal{L}}{\\partial \\theta^2}(x_1,...,x_n,\\theta) &= \\frac{2n}{\\theta^2} - \\frac{2}{\\theta^3} \\sum_{i=1}^n x_i\n\t\t\\end{align*}$$\n\tEn posant $\\theta_0 = \\frac{1}{2 n} \\sum_{i=1}^n x_i$, on a :\n\t$$\\begin{align*}\n\t\t\\frac{\\partial^2 \\ln \\mathcal{L}}{\\partial \\theta^2}(x_1,...,x_n,\\theta_0) &= \\frac{2}{\\theta_0} \\left(\\frac{n}{\\theta_0} - \\frac{1}{\\theta_0} \\times (2n)\\right) \\\\\n\t\t&= \\frac{-2n}{\\theta_0^2} < 0\n\t\\end{align*}$$\nDonc la fonction $\\theta \\mapsto \\ln \\mathcal{L}(x_1,...,x_n,\\theta)$ admet bien un maximum en $\\theta = \\theta_0$ pour tout $x_1,...,x_n$. On en déduit un estimateur de $\\theta$ : \t \\fbox{$\\hat{\\theta}=\\frac{1}{2 n} \\sum_{i=1}^n X_i$}.",
        "html": "<p>On définit un échantillon <span\nclass=\"math inline\">\\((X_1,...,X_n)\\)</span> de cette loi et on\nconsidère une réalisation quelconque <span\nclass=\"math inline\">\\((x_1,...,x_n)\\)</span> de cet échantillon. Le\nsupport de la loi étant l’intervalle <span\nclass=\"math inline\">\\(]0;+\\infty[\\)</span>, on peut supposer que pour\ntout <span class=\"math inline\">\\(i\\)</span>, <span\nclass=\"math inline\">\\(x_i &gt; 0\\)</span>.</p>\n<p>On exprime maintenant la log vraisemblance de cet échantillon : <span\nclass=\"math display\">\\[\\begin{align*}\n        \\ln \\mathcal{L}(x_1,...,x_n,\\theta) &amp;= \\ln \\prod_{i=1}^n\nf(x_i) \\\\\n        &amp;= -2n \\ln(\\theta) + \\sum_{i=1}^{n} \\ln(x_i)\n-\\frac{1}{\\theta} \\sum_{i=1}^{n} x_i \\\\\n        \\frac{\\partial \\ln \\mathcal{L}}{\\partial\n\\theta}(x_1,...,x_n,\\theta) = 0 &amp;\\iff \\theta = \\frac{1}{2 n}\n\\sum_{i=1}^n x_i \\\\\n        \\frac{\\partial^2 \\ln \\mathcal{L}}{\\partial\n\\theta^2}(x_1,...,x_n,\\theta) &amp;= \\frac{2n}{\\theta^2} -\n\\frac{2}{\\theta^3} \\sum_{i=1}^n x_i\n        \\end{align*}\\]</span> En posant <span\nclass=\"math inline\">\\(\\theta_0 = \\frac{1}{2 n} \\sum_{i=1}^n\nx_i\\)</span>, on a : <span class=\"math display\">\\[\\begin{align*}\n        \\frac{\\partial^2 \\ln \\mathcal{L}}{\\partial\n\\theta^2}(x_1,...,x_n,\\theta_0) &amp;= \\frac{2}{\\theta_0}\n\\left(\\frac{n}{\\theta_0} - \\frac{1}{\\theta_0} \\times (2n)\\right) \\\\\n        &amp;= \\frac{-2n}{\\theta_0^2} &lt; 0\n    \\end{align*}\\]</span> Donc la fonction <span\nclass=\"math inline\">\\(\\theta \\mapsto \\ln\n\\mathcal{L}(x_1,...,x_n,\\theta)\\)</span> admet bien un maximum en <span\nclass=\"math inline\">\\(\\theta = \\theta_0\\)</span> pour tout <span\nclass=\"math inline\">\\(x_1,...,x_n\\)</span>. On en déduit un estimateur\nde <span class=\"math inline\">\\(\\theta\\)</span> : .</p>\n"
      }
    },
    {
      "id": "4f1ec3f2-f0de-4175-930c-dbeee56c4416",
      "type": "question",
      "value": {
        "latex": "Déterminer le biais de cet estimateur.  \\\\(Indication : on admet que pour tout $n \\in \\N$, $\\int_0^{+\\infty} x^n e^{-x} \\, \\mathrm{d}x = n!$.)",
        "html": "<p>Déterminer le biais de cet estimateur.<br />\n(Indication : on admet que pour tout <span class=\"math inline\">\\(n \\in\n\\N\\)</span>, <span class=\"math inline\">\\(\\int_0^{+\\infty} x^n e^{-x} \\,\n\\mathrm{d}x = n!\\)</span>.)</p>\n"
      }
    },
    {
      "id": "648fea5f-0602-4a34-aea0-1dbfc67b4036",
      "type": "reponse",
      "value": {
        "latex": "On calcule l'espérance de cette loi : \n$$\\begin{align*}\n\\E(X_1) &= \\int xf(x)dx \\\\\n        &= \\int_0^{+\\infty} \\frac{x^2}{\\theta^2}e^{-\\frac{x}{\\theta}} dx \\\\\n        &= \\theta \\int_0^{+\\infty} {u^2}e^{-u} du \\\\\n        &= 2 \\theta \n\\end{align*}$$\t\nDonc par linéarité, l'espérance de $\\hat{\\theta}$ est $$\\E\\left(\\hat{\\theta}\\right) = \\frac{1}{2n} \\times n \\times 2 \\theta = \\theta$$\ndonc le biais de $\\hat{\\theta}$ est $$B(\\hat{\\theta}) = \\E(\\hat{\\theta} - \\theta) = 0$$",
        "html": "<p>On calcule l’espérance de cette loi : <span\nclass=\"math display\">\\[\\begin{align*}\n\\E(X_1) &amp;= \\int xf(x)dx \\\\\n        &amp;= \\int_0^{+\\infty}\n\\frac{x^2}{\\theta^2}e^{-\\frac{x}{\\theta}} dx \\\\\n        &amp;= \\theta \\int_0^{+\\infty} {u^2}e^{-u} du \\\\\n        &amp;= 2 \\theta\n\\end{align*}\\]</span> Donc par linéarité, l’espérance de <span\nclass=\"math inline\">\\(\\hat{\\theta}\\)</span> est <span\nclass=\"math display\">\\[\\E\\left(\\hat{\\theta}\\right) = \\frac{1}{2n} \\times\nn \\times 2 \\theta = \\theta\\]</span> donc le biais de <span\nclass=\"math inline\">\\(\\hat{\\theta}\\)</span> est <span\nclass=\"math display\">\\[B(\\hat{\\theta}) = \\E(\\hat{\\theta} - \\theta) =\n0\\]</span></p>\n"
      }
    }
  ]
}